{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Welcome to the 'Model Training and Prediction' notebook, a crucial facet of our project's data science pipeline. In this notebook, we offer a meticulous examination of our rigorous model development process. The pipeline starts by accepting training data, followed by fitting three distinct types of models to it: Random Forest, Gradient Boosted Tree, and XGBoost. The initial stages include encoding categorical variables and executing Recursive Feature Elimination (RFE) for feature selection. This is succeeded by the application of genetic algorithms to hyperparameter tuning, operating in tandem with a cross-validation routine. Subsequently, the best model is selected based on the highest F1 score, indicating the balance between precision and recall. Finally, the selected model is utilized to predict the outcomes for the current week's round of NRL matches. This process is iterative and cyclical, with the potential for revisiting earlier stages based on the model's performance. Let us proceed with this in-depth exploration.\n",
    "\n",
    "## Set up Environment\n",
    "This code segment is setting up the environment for the model training pipeline. It begins by importing sys and pathlib - Python libraries used for managing system parameters and file paths, respectively.\n",
    "\n",
    "The code then updates the system path to include the \"functions\" directory. This allows for the import of custom modules `modelling_functions`, `model_properties`, and `training_config` which are stored in this directory. These modules contain custom functions and configuration settings that are critical for the later stages of data preprocessing, model training, and prediction.\n",
    "\n",
    "Following this, the `project_root` variable is defined. This is achieved by using the pathlib library to establish the root directory of the project.\n",
    "\n",
    "Finally, the `db_path` variable is constructed. This is the relative path to the SQLite database \"footy-tipper-db.sqlite\", which is located in the \"data\" directory of the project root. This path will be used for database connectivity throughout the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "sys.path.append(\"functions\") \n",
    "import modelling_functions as mf\n",
    "import model_properties as mp\n",
    "import training_config as tc\n",
    "\n",
    "# Get to the root directory\n",
    "project_root = pathlib.Path().absolute().parent.parent\n",
    "\n",
    "# Now construct the relative path to your SQLite database\n",
    "db_path = project_root / \"data\" / \"footy-tipper-db.sqlite\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "Our process starts by establishing the root directory of the project and constructing the relative path to the 'footy-tipper-db.sqlite' database located within the 'data' directory. We then connect to this SQLite database and use a SQL query housed in the 'footy_tipping_data.sql' file, found in the 'sql' directory, to extract the required data. This data is loaded into a pandas DataFrame, footy_tipping_data, serving as the basis for our subsequent modeling activities. Upon successful extraction of the data, we ensure the database connection is closed, maintaining good coding practice and resource management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>round_id</th>\n",
       "      <th>round_name</th>\n",
       "      <th>game_number</th>\n",
       "      <th>game_state_name</th>\n",
       "      <th>start_time</th>\n",
       "      <th>start_time_utc</th>\n",
       "      <th>venue_name</th>\n",
       "      <th>city</th>\n",
       "      <th>crowd</th>\n",
       "      <th>...</th>\n",
       "      <th>away_prev_result_diff</th>\n",
       "      <th>prev_result_diff</th>\n",
       "      <th>home_elo</th>\n",
       "      <th>away_elo</th>\n",
       "      <th>elo_diff</th>\n",
       "      <th>home_elo_prob</th>\n",
       "      <th>away_elo_prob</th>\n",
       "      <th>elo_draw_prob</th>\n",
       "      <th>elo_prob_diff</th>\n",
       "      <th>home_ground_advantage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.020111e+10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.584044e+09</td>\n",
       "      <td>1.584004e+09</td>\n",
       "      <td>CommBank Stadium</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>21363.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1510.543309</td>\n",
       "      <td>1496.559437</td>\n",
       "      <td>13.983872</td>\n",
       "      <td>0.515806</td>\n",
       "      <td>0.468960</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.046846</td>\n",
       "      <td>8.766223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.020111e+10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.584122e+09</td>\n",
       "      <td>1.584083e+09</td>\n",
       "      <td>GIO Stadium</td>\n",
       "      <td>Canberra</td>\n",
       "      <td>10610.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1515.710707</td>\n",
       "      <td>1466.529375</td>\n",
       "      <td>49.181332</td>\n",
       "      <td>0.553042</td>\n",
       "      <td>0.410595</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.142447</td>\n",
       "      <td>9.452456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.020111e+10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.584126e+09</td>\n",
       "      <td>1.584090e+09</td>\n",
       "      <td>Queensland Country Bank Stadium</td>\n",
       "      <td>Townsville</td>\n",
       "      <td>22459.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1490.406173</td>\n",
       "      <td>1483.396900</td>\n",
       "      <td>7.009273</td>\n",
       "      <td>0.505936</td>\n",
       "      <td>0.478830</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.027106</td>\n",
       "      <td>2.220902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.020111e+10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.584198e+09</td>\n",
       "      <td>1.584158e+09</td>\n",
       "      <td>McDonald Jones Stadium</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>10239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1484.839646</td>\n",
       "      <td>1486.546635</td>\n",
       "      <td>-1.706988</td>\n",
       "      <td>0.493587</td>\n",
       "      <td>0.491179</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>6.906021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.020111e+10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.584207e+09</td>\n",
       "      <td>1.584167e+09</td>\n",
       "      <td>Accor Stadium</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1505.190449</td>\n",
       "      <td>1506.316339</td>\n",
       "      <td>-1.125890</td>\n",
       "      <td>0.494410</td>\n",
       "      <td>0.490356</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>3.330532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2.023111e+10</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Round 21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.690038e+09</td>\n",
       "      <td>1.690002e+09</td>\n",
       "      <td>Cbus Super Stadium</td>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>15362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1489.984964</td>\n",
       "      <td>1479.009557</td>\n",
       "      <td>10.975407</td>\n",
       "      <td>0.511551</td>\n",
       "      <td>0.473215</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.038335</td>\n",
       "      <td>1.319097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>2.023111e+10</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Round 21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.690047e+09</td>\n",
       "      <td>1.690011e+09</td>\n",
       "      <td>McDonald Jones Stadium</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>20392.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1514.952402</td>\n",
       "      <td>1528.123609</td>\n",
       "      <td>-13.171207</td>\n",
       "      <td>0.477345</td>\n",
       "      <td>0.507422</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>-0.030077</td>\n",
       "      <td>-6.718729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2.023111e+10</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Round 21</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.690054e+09</td>\n",
       "      <td>1.690018e+09</td>\n",
       "      <td>Queensland Country Bank Stadium</td>\n",
       "      <td>Townsville</td>\n",
       "      <td>20710.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1541.048829</td>\n",
       "      <td>1521.493601</td>\n",
       "      <td>19.555229</td>\n",
       "      <td>0.512441</td>\n",
       "      <td>0.451195</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.061246</td>\n",
       "      <td>-0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>2.023111e+10</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Round 21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.690121e+09</td>\n",
       "      <td>1.690085e+09</td>\n",
       "      <td>BlueBet Stadium</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>21525.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1545.682868</td>\n",
       "      <td>1435.666580</td>\n",
       "      <td>110.016288</td>\n",
       "      <td>0.656564</td>\n",
       "      <td>0.343436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313129</td>\n",
       "      <td>20.278597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2.023111e+10</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Round 21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>1.690128e+09</td>\n",
       "      <td>1.690092e+09</td>\n",
       "      <td>PointsBet Stadium</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>10634.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1514.378556</td>\n",
       "      <td>1490.119306</td>\n",
       "      <td>24.259250</td>\n",
       "      <td>0.518932</td>\n",
       "      <td>0.444704</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.074228</td>\n",
       "      <td>8.771169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          game_id  round_id round_name  game_number game_state_name  \\\n",
       "0    2.020111e+10       1.0    Round 1          1.0           Final   \n",
       "1    2.020111e+10       1.0    Round 1          2.0           Final   \n",
       "2    2.020111e+10       1.0    Round 1          3.0           Final   \n",
       "3    2.020111e+10       1.0    Round 1          4.0           Final   \n",
       "4    2.020111e+10       1.0    Round 1          5.0           Final   \n",
       "..            ...       ...        ...          ...             ...   \n",
       "722  2.023111e+10      21.0   Round 21          4.0           Final   \n",
       "723  2.023111e+10      21.0   Round 21          5.0           Final   \n",
       "724  2.023111e+10      21.0   Round 21          6.0           Final   \n",
       "725  2.023111e+10      21.0   Round 21          7.0           Final   \n",
       "726  2.023111e+10      21.0   Round 21          8.0           Final   \n",
       "\n",
       "       start_time  start_time_utc                       venue_name  \\\n",
       "0    1.584044e+09    1.584004e+09                 CommBank Stadium   \n",
       "1    1.584122e+09    1.584083e+09                      GIO Stadium   \n",
       "2    1.584126e+09    1.584090e+09  Queensland Country Bank Stadium   \n",
       "3    1.584198e+09    1.584158e+09           McDonald Jones Stadium   \n",
       "4    1.584207e+09    1.584167e+09                    Accor Stadium   \n",
       "..            ...             ...                              ...   \n",
       "722  1.690038e+09    1.690002e+09               Cbus Super Stadium   \n",
       "723  1.690047e+09    1.690011e+09           McDonald Jones Stadium   \n",
       "724  1.690054e+09    1.690018e+09  Queensland Country Bank Stadium   \n",
       "725  1.690121e+09    1.690085e+09                  BlueBet Stadium   \n",
       "726  1.690128e+09    1.690092e+09                PointsBet Stadium   \n",
       "\n",
       "           city    crowd  ... away_prev_result_diff prev_result_diff  \\\n",
       "0        Sydney  21363.0  ...                   NaN              NaN   \n",
       "1      Canberra  10610.0  ...                   NaN              NaN   \n",
       "2    Townsville  22459.0  ...                   NaN              NaN   \n",
       "3     Newcastle  10239.0  ...                   NaN              NaN   \n",
       "4        Sydney      NaN  ...                   NaN              NaN   \n",
       "..          ...      ...  ...                   ...              ...   \n",
       "722  Gold Coast  15362.0  ...                   2.0             -4.0   \n",
       "723   Newcastle  20392.0  ...                 -14.0             30.0   \n",
       "724  Townsville  20710.0  ...                 -28.0            102.0   \n",
       "725     Penrith  21525.0  ...                  -4.0             12.0   \n",
       "726      Sydney  10634.0  ...                  18.0             18.0   \n",
       "\n",
       "        home_elo     away_elo    elo_diff  home_elo_prob  away_elo_prob  \\\n",
       "0    1510.543309  1496.559437   13.983872       0.515806       0.468960   \n",
       "1    1515.710707  1466.529375   49.181332       0.553042       0.410595   \n",
       "2    1490.406173  1483.396900    7.009273       0.505936       0.478830   \n",
       "3    1484.839646  1486.546635   -1.706988       0.493587       0.491179   \n",
       "4    1505.190449  1506.316339   -1.125890       0.494410       0.490356   \n",
       "..           ...          ...         ...            ...            ...   \n",
       "722  1489.984964  1479.009557   10.975407       0.511551       0.473215   \n",
       "723  1514.952402  1528.123609  -13.171207       0.477345       0.507422   \n",
       "724  1541.048829  1521.493601   19.555229       0.512441       0.451195   \n",
       "725  1545.682868  1435.666580  110.016288       0.656564       0.343436   \n",
       "726  1514.378556  1490.119306   24.259250       0.518932       0.444704   \n",
       "\n",
       "     elo_draw_prob elo_prob_diff  home_ground_advantage  \n",
       "0         0.015234      0.046846               8.766223  \n",
       "1         0.036364      0.142447               9.452456  \n",
       "2         0.015234      0.027106               2.220902  \n",
       "3         0.015234      0.002408               6.906021  \n",
       "4         0.015234      0.004055               3.330532  \n",
       "..             ...           ...                    ...  \n",
       "722       0.015234      0.038335               1.319097  \n",
       "723       0.015234     -0.030077              -6.718729  \n",
       "724       0.036364      0.061246              -0.360000  \n",
       "725       0.000000      0.313129              20.278597  \n",
       "726       0.036364      0.074228               8.771169  \n",
       "\n",
       "[727 rows x 154 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = mf.get_training_data(db_path, 'sql/training_data.sql')\n",
    "training_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "During the modelling phase, the `train_and_select_best_model` function, part of our `modelling_functions` module, is invoked. This function initiates the training of three distinct models: XGBoost, Random Forest, and Gradient Boosting Classifier. It takes as input the footy tipping data, predictor variables, the outcome variable, and several configuration settings like whether to use Recursive Feature Elimination (RFE), the number of cross-validation folds, and the optimization metric, all sourced from the `training_config` module.\n",
    "\n",
    "The function first identifies categorical columns in the feature set for one-hot encoding, creating dummy variables for categorical features. Depending on the choice of using RFE, a feature elimination step may be included in the pipeline. Each model subsequently undergoes hyperparameter tuning using a genetic algorithm, facilitated by the `GASearchCV` function.\n",
    "\n",
    "All the models are then trained and evaluated through cross-validation. The best model, or `footy_tipper`, is selected based on the superior performance on the chosen optimization metric. Additionally, a `LabelEncoder`(`label_encoder`), used to encode the categorical target variable, is returned. This LabelEncoder is specific to the model that performed best. The selected model, encapsulated in a pipeline with pre-processing steps and hyperparameter tuning, is now ready for the prediction phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model training: XGBClassifier\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t100   \t0.704979\t0.0117729  \t0.730439   \t0.669806   \n",
      "1  \t148   \t0.715339\t0.00733655 \t0.730439   \t0.697345   \n",
      "2  \t136   \t0.72095 \t0.00407514 \t0.730439   \t0.709787   \n",
      "3  \t150   \t0.723566\t0.00321149 \t0.730439   \t0.715257   \n",
      "4  \t136   \t0.725935\t0.00266092 \t0.7318     \t0.720775   \n",
      "5  \t143   \t0.728014\t0.00201165 \t0.733198   \t0.723533   \n",
      "6  \t136   \t0.72946 \t0.0020776  \t0.733198   \t0.723533   \n",
      "7  \t137   \t0.730813\t0.00179901 \t0.733198   \t0.726282   \n",
      "8  \t136   \t0.731806\t0.00147417 \t0.733198   \t0.727662   \n",
      "9  \t146   \t0.732124\t0.00133971 \t0.733198   \t0.726273   \n",
      "10 \t146   \t0.732611\t0.0011622  \t0.733198   \t0.724913   \n",
      "11 \t135   \t0.733126\t0.000660595\t0.735947   \t0.7318     \n",
      "12 \t143   \t0.733225\t0.000435388\t0.735947   \t0.7318     \n",
      "13 \t137   \t0.733266\t0.000354551\t0.735947   \t0.733198   \n",
      "14 \t128   \t0.733348\t0.000578293\t0.735947   \t0.733198   \n",
      "15 \t146   \t0.733526\t0.000973637\t0.735947   \t0.729051   \n",
      "16 \t137   \t0.73399 \t0.00121566 \t0.735947   \t0.729051   \n",
      "17 \t133   \t0.734828\t0.00116277 \t0.735947   \t0.733198   \n",
      "18 \t138   \t0.735351\t0.00143971 \t0.735947   \t0.726254   \n",
      "19 \t145   \t0.735809\t0.000903077\t0.735947   \t0.727681   \n",
      "20 \t135   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "21 \t146   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "22 \t137   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "23 \t140   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "24 \t137   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "25 \t138   \t0.735878\t0.000684318\t0.735947   \t0.729069   \n",
      "26 \t149   \t0.735892\t0.000548959\t0.735947   \t0.73043    \n",
      "27 \t155   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "28 \t128   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "29 \t145   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "30 \t148   \t0.735892\t0.000548959\t0.735947   \t0.73043    \n",
      "31 \t138   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "32 \t140   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "33 \t141   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "34 \t148   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "35 \t145   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "36 \t151   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "37 \t141   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "38 \t124   \t0.735878\t0.000686198\t0.735947   \t0.729051   \n",
      "39 \t145   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "40 \t135   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "41 \t137   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "42 \t139   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "43 \t142   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "44 \t146   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "45 \t141   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "46 \t151   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "47 \t137   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "48 \t129   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "49 \t141   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "50 \t145   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "51 \t142   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "52 \t138   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "53 \t148   \t0.735892\t0.000548959\t0.735947   \t0.73043    \n",
      "54 \t134   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "55 \t154   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "56 \t141   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "57 \t146   \t0.735892\t0.000548019\t0.735947   \t0.730439   \n",
      "58 \t149   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "59 \t148   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "60 \t153   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "61 \t144   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "62 \t152   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "63 \t137   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "64 \t138   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "65 \t144   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "66 \t129   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "67 \t150   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "68 \t130   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "69 \t137   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "70 \t143   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "71 \t139   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "72 \t150   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "73 \t140   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "74 \t138   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "75 \t138   \t0.735947\t3.33067e-16\t0.735947   \t0.735947   \n",
      "Number of features selected: 46\n",
      "Best parameters: {'n_estimators': 64, 'learning_rate': 0.05194618837710391, 'max_depth': 2, 'subsample': 0.9059111048342069, 'colsample_bytree': 0.8625104557646598, 'gamma': 0.6819263589753357}\n",
      "Best score: 0.7359470949456779\n",
      "\n",
      "\n",
      "Model training: RandomForestClassifier\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRFECV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m footy_tipper, label_encoder \u001b[39m=\u001b[39m mf\u001b[39m.\u001b[39;49mtrain_and_select_best_model(\n\u001b[1;32m      2\u001b[0m     training_data, tc\u001b[39m.\u001b[39;49mpredictors, tc\u001b[39m.\u001b[39;49moutcome_var,\n\u001b[1;32m      3\u001b[0m     tc\u001b[39m.\u001b[39;49muse_rfe, tc\u001b[39m.\u001b[39;49mnum_folds, tc\u001b[39m.\u001b[39;49mopt_metric\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m footy_tipper\n",
      "File \u001b[0;32m~/Documents/GitHub/footy-tipper/pipeline/model-training/functions/modelling_functions.py:187\u001b[0m, in \u001b[0;36mtrain_and_select_best_model\u001b[0;34m(data, predictors, outcome_var, use_rfe, num_folds, opt_metric)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39m# Train each model and keep track of the best one\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39mfor\u001b[39;00m estimator, param_grid \u001b[39min\u001b[39;00m models_and_params:\n\u001b[0;32m--> 187\u001b[0m     label_encoder, pipeline \u001b[39m=\u001b[39m train_model_pipeline(\n\u001b[1;32m    188\u001b[0m         data, predictors, outcome_var,\n\u001b[1;32m    189\u001b[0m         estimator, param_grid,\n\u001b[1;32m    190\u001b[0m         use_rfe\u001b[39m=\u001b[39;49muse_rfe, num_folds\u001b[39m=\u001b[39;49mnum_folds,\n\u001b[1;32m    191\u001b[0m         opt_metric\u001b[39m=\u001b[39;49mopt_metric\n\u001b[1;32m    192\u001b[0m     )\n\u001b[1;32m    194\u001b[0m     score \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mhyperparamtuning\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mbest_score_\n\u001b[1;32m    196\u001b[0m     \u001b[39m# Update best_model, best_score, etc.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/footy-tipper/pipeline/model-training/functions/modelling_functions.py:121\u001b[0m, in \u001b[0;36mtrain_model_pipeline\u001b[0;34m(data, predictors, outcome_var, estimator, param_grid, use_rfe, num_folds, opt_metric)\u001b[0m\n\u001b[1;32m    118\u001b[0m pipeline \u001b[39m=\u001b[39m create_pipeline(estimator, param_grid, use_rfe, num_folds, opt_metric, cat_cols)\n\u001b[1;32m    120\u001b[0m \u001b[39m# Fit the pipeline\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m use_rfe:\n\u001b[1;32m    124\u001b[0m     \u001b[39m# Print the number of features selected\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     num_features_selected \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mfeature_elimination\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mn_features_\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 416\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    417\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/pipeline.py:370\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    368\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    369\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    371\u001b[0m     cloned_transformer,\n\u001b[1;32m    372\u001b[0m     X,\n\u001b[1;32m    373\u001b[0m     y,\n\u001b[1;32m    374\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    375\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    376\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    377\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    378\u001b[0m )\n\u001b[1;32m    379\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    949\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 950\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    951\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py:679\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the RFE model and automatically tune the number of selected features.\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \n\u001b[1;32m    656\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m tags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()\n\u001b[0;32m--> 679\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    680\u001b[0m     X,\n\u001b[1;32m    681\u001b[0m     y,\n\u001b[1;32m    682\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    683\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m    684\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m tags\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mallow_nan\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m    685\u001b[0m     multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    686\u001b[0m )\n\u001b[1;32m    688\u001b[0m \u001b[39m# Initialization\u001b[39;00m\n\u001b[1;32m    689\u001b[0m cv \u001b[39m=\u001b[39m check_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:883\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39missparse(array):\n\u001b[1;32m    882\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 883\u001b[0m     array \u001b[39m=\u001b[39m _ensure_sparse_format(\n\u001b[1;32m    884\u001b[0m         array,\n\u001b[1;32m    885\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    886\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    887\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    888\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    889\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m    890\u001b[0m         estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    891\u001b[0m         input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    892\u001b[0m     )\n\u001b[1;32m    893\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m     \u001b[39m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    895\u001b[0m     \u001b[39m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    896\u001b[0m     \u001b[39m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    897\u001b[0m     \u001b[39m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39m# of warnings context manager.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:573\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    568\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    569\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt check \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m sparse matrix for nan or inf.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m spmatrix\u001b[39m.\u001b[39mformat,\n\u001b[1;32m    570\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    571\u001b[0m         )\n\u001b[1;32m    572\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 573\u001b[0m         _assert_all_finite(\n\u001b[1;32m    574\u001b[0m             spmatrix\u001b[39m.\u001b[39;49mdata,\n\u001b[1;32m    575\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    576\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    577\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    578\u001b[0m         )\n\u001b[1;32m    580\u001b[0m \u001b[39mreturn\u001b[39;00m spmatrix\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRFECV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "footy_tipper, label_encoder = mf.train_and_select_best_model(\n",
    "    training_data, tc.predictors, tc.outcome_var,\n",
    "    tc.use_rfe, tc.num_folds, tc.opt_metric\n",
    ")\n",
    "\n",
    "footy_tipper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display feature importance\n",
    "The `get_feature_importance` function retrieves feature importances from a trained scikit-learn pipeline. It accounts for different transformations, such as one-hot encoding and recursive feature elimination. The function then returns a sorted DataFrame listing each feature alongside its respective importance, aiding in understanding the model's decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_df = mp.get_feature_importances_from_pipeline(footy_tipper, tc.predictors)\n",
    "# feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "The `save_models` function stores the trained LabelEncoder and Pipeline objects to the disk. This allows for easy retrieval and reuse in future model prediction tasks, without the need to retrain these components. The objects are stored in a designated 'models' directory under the project root path, ensuring organized and consistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.save_models(label_encoder, footy_tipper, project_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
